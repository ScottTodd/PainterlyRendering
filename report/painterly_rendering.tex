\documentclass[conference]{acmsiggraph}

\TOGonlineid{45678}
\TOGvolume{0}
\TOGnumber{0}
\TOGarticleDOI{1111111.2222222}
\TOGprojectURL{}
\TOGvideoURL{}
\TOGdataURL{}
\TOGcodeURL{}

\title{Painterly Rendering for WebGL}

\author{Andy Hanson\thanks{email: hansoa2@rpi.edu}\\
        Scott Todd\thanks{email: todds@rpi.edu}}
\pdfauthor{Robert A. Smith}

\keywords{radiosity, global illumination, constant time}

\begin{document}

\teaser{
  \includegraphics[height=2.0in]{images/teapot_bronze}
  \caption{The Utah teapot rendered using our system.}
}

\maketitle

\begin{abstract}

TODO.

\end{abstract}

%%% The ``CRCatlist'' environment defines one or more ACM ``Computing Review''
%%% (or ``CR'') categories, used for indexing your work. For more information
%%% on CR categories, please see http://www.acm.org/class/1998.

% \begin{CRcatlist}
%   \CRcat{I.3.3}{Computer Graphics}{Three-Dimensional Graphics and Realism}{Display Algorithms}
%   \CRcat{I.3.7}{Computer Graphics}{Three-Dimensional Graphics and Realism}{Radiosity};
% \end{CRcatlist}

\keywordlist

%% Use this only if you're preparing a technical paper to be published in the
%% ACM 'Transactions on Graphics' journal.

\TOGlinkslist

%% Required for all content.

\copyrightspace

\section{Introduction}

TODO.

(Link to GitHub and hosted url)


\subsection{Related Work}

The use of particle systems to create painted images was explored in
``Painterly Rendering for Animation'' \cite{Meier:1996:PRA:237170.237288}.
Paint particles are distributed onto 3D objects and undergo the same
transormation. During the rendering phase, a reference picture rendering is
first created using traditional methods. Then every particle is sorted by
depth, and particles are drawn back-to-front. Particles take on the color of
the reference picture, or a solid color may be used per-particle and the
reference picture ignored. The color is applied to a stroke texture (called
the ``brush image''), which is finally applied to the screen at the particle's
(projected) location.

In \cite{Hertzmann:1998:PRC:280814.280951}, 2D input images are painted over
by layers of spline brush strokes. Strokes are placed along areas of high
gradient on a source image blurred proportionally to the current brush size. In
this manner, progressive emphasis is  placed on regions of high visual
interest. An intuitive collection of parameters is chosen such that a user may
easily select between a spectrum of visual styles. Parameter sets are presented
for ``Impressionist'', ``Expressionist'', ``Colorist Wash'', and ``Pointillist''
styles.

\cite{Kalnins:2002:WND:566570.566648} explores interactive techniques that
allow artists to create non-photorealistic renderings of 3D models. Artists are
given control over brush styles, paper textures, basecoats, background styles,
and the position and styling of each stroke. Their system uses information
supplied from one or more viewpoints to render the models at any new viewpoint
while preserving the desired aesthetic.


\section{Painterly Rendering System}

\subsection{Algorithm Overview}

We represent brush strokes as particles within particle systems. (The particles
will be referred to as ``strokes''.) Each object in the scene is represented as
any number of layers; each layer has its own particle system.

Our system creates stroke meshes out of traditional three.js meshes. Other
inputs will include layer and coloring information. The system outputs a
painterly image to a WebGL canvas.


\subsection{Stroke Selection}

Rather than storing models directly as stroke systems, our system loads
three.js JSON object files. These are transformed into stroke systems in the
client using a method similar to that of \cite{Meier:1996:PRA:237170.237288}.
The total number of particles to be placed on the mesh is a parameter. Then for
each face on the mesh, the number of particles on that face is in proportion to
its area; in other words, it is that face's fraction of the total area, times
the total number of particles. Random Barycentric coordinates are selected, and
position, normal, and u/v values are interpolated between the face's vertices.

Particles of a single layer are drawn in the same order every time, so if
particles are generated one face at a time in this way, rendered images will
show an undesirable ordering of particles. So, a stroke particles are shuffled
once during the loading phase.


\subsection{Colors}

To color particles, the user may select random hue, saturation, and luminance
ranges for particles to be chosen from. This produces aesthetically pleasing
representations of what are essentially ``solid'' colored objects.

We are also exploring the use of textures.


\subsection{Stroke Rendering}

\subsubsection{zQuality}

\begin{figure*}[ht] % figure* allows for this to span the full page width
  \centering
  \includegraphics[width=6.0in]{images/torus_depth_test_demo}
  \caption{The image on the right discards fragments whose depth values differ
           from the value stored in the depth buffer texture while the image on
           the left does not. Note the intersections and other artifacts on the
           left.}
\end{figure*}

Good results may be achieved by sorting particles by depth, but at the cost of
performance. Blending particles is also unsuccessful because the number of
overlapping particles is unpredictable. So, within each layer, particles are
always drawn in the same order and always draw on top of each other. This leads
to occlusion issues when a layer overlaps itself, shown in Figure 2.

To mitigate this effect, we render in two passes. First, we render the original
geometry into a floating point depth buffer texture.

In the first iteration of our algorithm, we discarded fragments whose depth
values differ from the value stored in the depth buffer at that position. This
method performs a sharp cut-off around the silhouette of each object, so it
conflicted with the painterly rendering focus of our project.

This depth texture is passed as a uniform into the vertex shader for paint
strokes. Each stroke measures its depth compared to the expected depth, and
fades out when there is a discrepancy. (A simple on/off threshold would work,
but strokes just showing up coming around the edge of an object would suddenly
``pop'' into existence.)

There is still another problem for strokes just at the edge of an object, which
do not frames share its depth buffer. A slight fattening of the original mesh
ensures that all of its strokes fit within its borders. We expanded the
original mesh by pushing each vertex a small distance along the normal at that
vertex.

\subsubsection{Lighting}

Each stroke is solidly colored using the light calculated at its center. We use
the Phong equations. These are calculated per stroke (in the vertex shader),
making our method more efficient than first creating a reference image. The
total diffuse and specular lighting are calculated separately (see the section
on specular fade in).


\subsubsection{Gradient Estimation}

\begin{figure*}[ht]
  \centering
  \includegraphics[width=6.0in]{images/sphere_rotation_curve}
  \caption{From left to right: no orientation or curvature, orientation with
           no curvature, orientation and exaggerated curvature (2.0).}
\end{figure*}

TODO.

\subsubsection{Layering}

As in \cite{Hertzmann:1998:PRC:280814.280951},
\cite{Meier:1996:PRA:237170.237288}, (and others?), we use multiple layers of
brush strokes for each object. While the layer properties can be
user-controller, we intend for the base layers to contain a smaller quantity of
larger brush strokes and the top layers to contain a larger quantity of smaller
brush strokes. The base layers capture rough details and cover the entirety of
the original mesh, while the top layers show fine details and are expected to
leave gaps between each other. We found that three layers of strokes was
sufficient for the scenes that we tested.

We support using a specular threshold and specular fade in to control the
visibility of strokes within a layer. If the specular lighting contribution at
a stroke does not exceed the minimum value, it is discarded. Similarly, if a
stroke has low specular, we change its alpha value based on the specular fade
in. This allows us to approximate the visual interest sampling in
\cite{Hertzmann:1998:PRC:280814.280951} and (other reference).


\subsection{Parameters List}

TODO.

\section{Results}

TODO.

\begin{figure}[ht]
  \centering
  \includegraphics[width=3.3in]{images/bunny_with_fade_in}
  \caption{The Stanford bunny rendered using three layers of brush strokes.
           The topmost layer uses a minimum specular cutoff of 0.95 and a
           specular fade-in of 0.63.}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=3.3in]{images/teapot_with_background}
  \caption{The Utah teapot rendered using three layers of brush strokes.
           The topmost layer uses a specular fade-in of 0.03.}
\end{figure}

\section{Limitations}

TODO.

\section{Future Work}

TODO.

\section{Conclusion}

TODO.

\section*{Acknowledgements}

(TODO) Three.js

\bibliographystyle{acmsiggraph}
\bibliography{painterly_rendering}
\end{document}
